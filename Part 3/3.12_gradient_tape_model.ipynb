{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.12_gradient_tape_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NLOwP-ri6GS"
      },
      "source": [
        "[구글 코랩(Colab)에서 실행하기](https://colab.research.google.com/github/lovedlim/tensorflow/blob/main/Part%203/3.12_gradient_tape_model.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2BC-Ex4oF2x"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# 케라스의 내장 데이터셋에서 mnist 데이터셋을 로드\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# load_data()로 데이터셋을 로드 합니다.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 데이터 정규화\n",
        "x_train = x_train / x_train.max()\n",
        "x_test = x_test / x_test.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G2fYmFqoCIu"
      },
      "source": [
        "## 8-3-3. GradientTape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsIKuwHDoTU8"
      },
      "source": [
        "# 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
        "    tf.keras.layers.Dense(256, activation='relu'), \n",
        "    tf.keras.layers.Dense(64, activation='relu'), \n",
        "    tf.keras.layers.Dense(32, activation='relu'), \n",
        "    tf.keras.layers.Dense(10, activation='softmax'), \n",
        "])\n",
        "\n",
        "# 손실함수 정의\n",
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# 옵티마이저 정의\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvyVSAcwoWub"
      },
      "source": [
        "# 기록을 위한 Metric 정의\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
        "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5k4scKwoiq_"
      },
      "source": [
        "# 배치 생성 함수\n",
        "def get_batches(x, y, batch_size=32):\n",
        "    for i in range(int(x.shape[0] // batch_size)):\n",
        "        x_batch = x[i * batch_size: (i + 1) * batch_size]\n",
        "        y_batch = y[i * batch_size: (i + 1) * batch_size]\n",
        "        yield (np.asarray(x_batch), np.asarray(y_batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6urDBHroYke"
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    # GradientTape 적용\n",
        "    with tf.GradientTape() as tape:\n",
        "        # 예측\n",
        "        prediction = model(images, training=True)\n",
        "        # 손실\n",
        "        loss = loss_function(labels, prediction)\n",
        "    # 미분 (gradient) 값 계산\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    # optimizer 적용\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    # loss, accuracy 계산\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, prediction)\n",
        "\n",
        "@tf.function\n",
        "def valid_step(images, labels):\n",
        "    # 예측\n",
        "    prediction = model(images, training=False)    \n",
        "    # 손실\n",
        "    loss = loss_function(labels, prediction)\n",
        "\n",
        "    # loss, accuracy 계산\n",
        "    valid_loss(loss)\n",
        "    valid_accuracy(labels, prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T8bCr5HoaHr",
        "outputId": "e5b73667-c7c0-4e05-98ea-8bc2afc0fe3c"
      },
      "source": [
        "# 초기화 코드\n",
        "train_loss.reset_states()\n",
        "train_accuracy.reset_states()\n",
        "valid_loss.reset_states()\n",
        "valid_accuracy.reset_states()\n",
        "\n",
        "# Epoch 반복\n",
        "for epoch in range(5):\n",
        "    # batch 별 순회\n",
        "    for images, labels in get_batches(x_train, y_train):\n",
        "        # train_step\n",
        "        train_step(images, labels)    \n",
        "\n",
        "    for images, labels in get_batches(x_test, y_test):\n",
        "        # valid_step\n",
        "        valid_step(images, labels)\n",
        "\n",
        "    # 결과 출력\n",
        "    metric_template = 'epoch: {}, loss: {:.4f}, acc: {:.2f}%, val_loss: {:.4f}, val_acc: {:.2f}%'\n",
        "    print(metric_template.format(epoch+1, train_loss.result(), train_accuracy.result()*100, \n",
        "                                 valid_loss.result(), valid_accuracy.result()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, loss: 0.2409, acc: 92.81%, val_loss: 0.1575, val_acc: 95.00%\n",
            "epoch: 2, loss: 0.1717, acc: 94.87%, val_loss: 0.1387, val_acc: 95.58%\n",
            "epoch: 3, loss: 0.1363, acc: 95.92%, val_loss: 0.1339, val_acc: 95.88%\n",
            "epoch: 4, loss: 0.1146, acc: 96.56%, val_loss: 0.1265, val_acc: 96.24%\n",
            "epoch: 5, loss: 0.0991, acc: 97.01%, val_loss: 0.1256, val_acc: 96.43%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}